{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_show_predict-result.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuOkada/Sphere_CNN/blob/master/Video_show_predict_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RbsG-pVrvZH",
        "colab_type": "text"
      },
      "source": [
        "Time elapsed since Colab Instance was started: Shutdown in 0.5day(43200 second)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4UK0kSyrvOs",
        "colab_type": "code",
        "outputId": "056989db-f87d-44ce-ef15-95497f8c9f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00399514days (345.18sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnJ5O_PsRx62",
        "colab_type": "text"
      },
      "source": [
        "Connect to Google Drive File Stream\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hpTBhj4Rkuv",
        "colab_type": "code",
        "outputId": "1aa4818f-8938-45e2-f8e1-caae7f83a28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KyXAso3qHDc",
        "colab_type": "text"
      },
      "source": [
        "Sphere Predict (11:9) , *shape(90,110,3) , 8Class*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH3kY6sIfqjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "root_dir = \"./gdrive/My Drive/Google Colab/CO191219_proj\"\n",
        "\n",
        "#Load saved-model\n",
        "model = model_from_json(open(root_dir+'/Conv2D3-Dence3-Adadelta_v2/img_predict_Conv2D3-Dence3-Adadelta.json').read())\n",
        "#Load saved-weight\n",
        "model.load_weights(root_dir+'/Conv2D3-Dence3-Adadelta_v2/img_predict_Conv2D3-Dence3-Adadelta.hdf5')\n",
        "#Define categories\n",
        "categories = [\"ceiling\", \"cloth\", \"floor\", \"floor-object\",\"hole\", \"human\", \"object\", \"wall\"]\n",
        "\n",
        "#Define constant\n",
        "ESC_KEY = 27     # Esc Key\n",
        "INTERVAL= 1     # Interval\n",
        "FRAME_RATE = 5  #Video fps\n",
        "\n",
        "#Load original video file\n",
        "mov_org = cv2.VideoCapture(root_dir + \"/demovideo/demovideo.m4v\")\n",
        "ret, frame = mov_org.read()\n",
        "\n",
        "#Define Output-video properties\n",
        "font = cv2.FONT_HERSHEY_PLAIN #Font for output-video\n",
        "font_size = 1.8 #Font size for output-video\n",
        "font_boldness = 2 #Font Boldness for output-video\n",
        "width = int(mov_org.get(cv2.CAP_PROP_FRAME_WIDTH)) #Get original movie width\n",
        "height = int(mov_org.get(cv2.CAP_PROP_FRAME_HEIGHT)) #Get original movie height\n",
        "fps = mov_org.get(cv2.CAP_PROP_FPS) #Get original movie width\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') #Define Videowriter in opencv for output\n",
        "#mov_out = cv2.VideoWriter(root_dir + \"/demovideo/demovideo_out_v1.mp4\", fourcc, fps, (width,height)) #Define output-video codec\n",
        "mov_out = cv2.VideoWriter(root_dir + \"/demovideo/demovideo_out_v1.m4v\", fourcc, fps, (width,height)) #Define output-video codec\n",
        "\n",
        "#Loop while original video is remaining\n",
        "while ret == True:\n",
        "    #Shift int-type to float-type\n",
        "    flt32_frame = frame.astype(np.float32)\n",
        "    \n",
        "    #Define numpy-array for predict-result\n",
        "    predict_result = np.empty(0)\n",
        "\n",
        "    #Process entire image by CNN\n",
        "    for vartical_index in range(0, 972, 108):\n",
        "        for horizontal_index in range(15, 1770, 135):\n",
        "          \n",
        "          #print(str(horizontal_index) + \",\" + str(vartical_index))\n",
        "\n",
        "          if ((vartical_index % 216 == 0) and ((horizontal_index-15) % 270 == 0)) or vartical_index >= 540:\n",
        "\n",
        "              fr = frame[vartical_index:vartical_index+215, horizontal_index:horizontal_index+269]\n",
        "              cv2.imwrite(root_dir  + \"/demovideo/temp_frame.jpg\", fr)\n",
        "\n",
        "              img = image.load_img(root_dir  + \"/demovideo/temp_frame.jpg\", target_size=(90, 110, 3))\n",
        "              x = image.img_to_array(img)\n",
        "              x = np.expand_dims(x, axis=0)\n",
        "\n",
        "              features = model.predict(x)\n",
        "              #print(features)\n",
        "              max_features = np.amax(features)\n",
        "\n",
        "              if max_features == 0:\n",
        "                  predict_result = np.append(predict_result, 0)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, \"error\", (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              elif features[0,0] == max_features:\n",
        "                  predict_result = np.append(predict_result, 1)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(164,142,199), thickness=-1)\n",
        "                  cv2.putText(frame, categories[0], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(164,142,199), font_boldness)\n",
        "              elif features[0,1] == max_features:\n",
        "                  predict_result = np.append(predict_result, 2)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(164,142,199), thickness=-1)\n",
        "                  cv2.putText(frame, categories[1], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(164,142,199), font_boldness)\n",
        "              elif features[0,2] == max_features:\n",
        "                  predict_result = np.append(predict_result, 3)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (113,208,255), thickness=-1)\n",
        "                  cv2.putText(frame, categories[2], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(113,208,255), font_boldness)\n",
        "              elif features[0,3] == max_features:\n",
        "                  predict_result = np.append(predict_result, 4)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[3], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              elif features[0,4] == max_features:\n",
        "                  predict_result = np.append(predict_result, 5)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[4], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              elif features[0,5] == max_features:\n",
        "                  predict_result = np.append(predict_result, 6)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[5], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              elif features[0,6] == max_features:\n",
        "                  predict_result = np.append(predict_result, 7)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[6], (horizontal_index+135+3, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              elif features[0,7] == max_features:\n",
        "                  predict_result = np.append(predict_result, 8)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[7], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "              else:\n",
        "                  predict_result = np.append(predict_result, 0)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (244,121,128), thickness=-1)\n",
        "                  cv2.putText(frame, \"error\", (horizontal_index+135+5, vartical_index+108+5), font, font_size,(244,121,128), font_boldness)\n",
        "\n",
        "          else:\n",
        "              predict_result = np.append(predict_result, 0)\n",
        "              #print(\"out\")\n",
        "\n",
        "    predict_result = predict_result.reshape(9,13)\n",
        "    #print(predict_result)\n",
        "\n",
        "    #Write for movie\n",
        "    mov_out.write(frame)\n",
        "\n",
        "    #if Esc Key is pushed, Escape loop\n",
        "    key = cv2.waitKey(INTERVAL)\n",
        "    if key == ESC_KEY:\n",
        "        break\n",
        "\n",
        "    #Load next video-frame\n",
        "    ret, frame = mov_org.read()\n",
        "\n",
        "#End\n",
        "cv2.destroyAllWindows()\n",
        "mov_org.release()\n",
        "mov_out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Uvk9DOqF0y",
        "colab_type": "text"
      },
      "source": [
        "Sphere Predict (11:9), *shape(60,70,3) , 7-false8-Class*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E3KplfpqGJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "1aa09926-e0d3-47ae-9130-afd5fe0e08f6"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "root_dir = \"./gdrive/My Drive/Google Colab/CO191219_proj\"\n",
        "\n",
        "#Load saved-model\n",
        "model = model_from_json(open(root_dir+'/Conv2D3-Dence3-Adadelta_v4/img_predict_Conv2D3-Dence3-Adadelta.json').read())\n",
        "#Load saved-weight\n",
        "model.load_weights(root_dir+'/Conv2D3-Dence3-Adadelta_v4/img_predict_Conv2D3-Dence3-Adadelta.hdf5')\n",
        "#Define categories\n",
        "categories = [\"floor1\", \"floor2\", \"floor-object\", \"object\", \"wall\", \"hole\", \"human\",\"ceiling\"]\n",
        "\n",
        "#Define constant\n",
        "ESC_KEY = 27     # Esc Key\n",
        "INTERVAL= 1     # Interval\n",
        "FRAME_RATE = 5  #Video fps\n",
        "\n",
        "#Load original video file\n",
        "mov_org = cv2.VideoCapture(root_dir + \"/demovideo/demovideo_short.m4v\")\n",
        "ret, frame = mov_org.read()\n",
        "\n",
        "#Define Output-video properties\n",
        "font = cv2.FONT_HERSHEY_PLAIN #Font for output-video\n",
        "font_size = 1.8 #Font size for output-video\n",
        "font_boldness = 2 #Font Boldness for output-video\n",
        "width = int(mov_org.get(cv2.CAP_PROP_FRAME_WIDTH)) #Get original movie width\n",
        "height = int(mov_org.get(cv2.CAP_PROP_FRAME_HEIGHT)) #Get original movie height\n",
        "fps = mov_org.get(cv2.CAP_PROP_FPS) #Get original movie width\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') #Define Videowriter in opencv for output\n",
        "#mov_out = cv2.VideoWriter(root_dir + \"/demovideo/demovideo_out_v1.mp4\", fourcc, fps, (width,height)) #Define output-video codec\n",
        "mov_out = cv2.VideoWriter(root_dir + \"/demovideo/demovideo_out_v3.m4v\", fourcc, fps, (width,height)) #Define output-video codec\n",
        "\n",
        "#Loop while original video is remaining\n",
        "while ret == True:\n",
        "    #Shift int-type to float-type\n",
        "    flt32_frame = frame.astype(np.float32)\n",
        "    \n",
        "    #Define numpy-array for predict-result\n",
        "    predict_result = np.empty(0)\n",
        "\n",
        "    #Process entire image by CNN\n",
        "    for vartical_index in range(0, 972, 108):\n",
        "        for horizontal_index in range(15, 1770, 135):\n",
        "          \n",
        "          #print(str(horizontal_index) + \",\" + str(vartical_index))\n",
        "\n",
        "          if ((vartical_index % 216 == 0) and ((horizontal_index-15) % 270 == 0)) or vartical_index >= 540:\n",
        "\n",
        "              fr = frame[vartical_index:vartical_index+215, horizontal_index:horizontal_index+269]\n",
        "              cv2.imwrite(root_dir  + \"/demovideo/temp_frame.jpg\", fr)\n",
        "\n",
        "              img = image.load_img(root_dir  + \"/demovideo/temp_frame.jpg\", target_size=(60, 70, 3))\n",
        "              x = image.img_to_array(img)\n",
        "              x = np.expand_dims(x, axis=0)\n",
        "\n",
        "              features = model.predict(x)\n",
        "              #print(features)\n",
        "              max_features = np.amax(features)\n",
        "\n",
        "              if max_features == 0:\n",
        "                  predict_result = np.append(predict_result, 0)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (255,255,255), thickness=-1)\n",
        "                  cv2.putText(frame, \"error\", (horizontal_index+135+5, vartical_index+108+5), font, font_size,(255,255,255), font_boldness)\n",
        "              elif features[0,0] == max_features:\n",
        "                  predict_result = np.append(predict_result, 1)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(160,255,60), thickness=-1)\n",
        "                  cv2.putText(frame, categories[0], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(160,255,60), font_boldness)\n",
        "              elif features[0,1] == max_features:\n",
        "                  predict_result = np.append(predict_result, 2)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(160,255,60), thickness=-1)\n",
        "                  cv2.putText(frame, categories[1], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(160,255,60), font_boldness)\n",
        "              elif features[0,2] == max_features:\n",
        "                  predict_result = np.append(predict_result, 3)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (220,64,255), thickness=-1)\n",
        "                  cv2.putText(frame, categories[2], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(220,64,255), font_boldness)\n",
        "              elif features[0,3] == max_features:\n",
        "                  predict_result = np.append(predict_result, 4)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (180,140,255), thickness=-1)\n",
        "                  cv2.putText(frame, categories[3], (horizontal_index+135+5, vartical_index+108+5), font, font_size, (180,140,255), font_boldness)\n",
        "              elif features[0,4] == max_features:\n",
        "                  predict_result = np.append(predict_result, 5)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (128,128,0), thickness=-1)\n",
        "                  cv2.putText(frame, categories[4], (horizontal_index+135+5, vartical_index+108+5), font, font_size, (128,128,0), font_boldness)\n",
        "              elif features[0,5] == max_features:\n",
        "                  predict_result = np.append(predict_result, 6)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (128,255,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[5], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(128,255,128), font_boldness)\n",
        "              elif features[0,6] == max_features:\n",
        "                  predict_result = np.append(predict_result, 7)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5,(0,0,0), thickness=-1)\n",
        "                  cv2.putText(frame, categories[6], (horizontal_index+135+3, vartical_index+108+5), font, font_size,(0,0,0), font_boldness)\n",
        "              elif features[0,7] == max_features:\n",
        "                  predict_result = np.append(predict_result, 8)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (128,255,128), thickness=-1)\n",
        "                  cv2.putText(frame, categories[7], (horizontal_index+135+5, vartical_index+108+5), font, font_size,(128,255,128), font_boldness)\n",
        "              else:\n",
        "                  predict_result = np.append(predict_result, 0)\n",
        "                  cv2.circle(frame, (horizontal_index+135, vartical_index+108), 5, (255,255,255), thickness=-1)\n",
        "                  cv2.putText(frame, \"error\", (horizontal_index+135+5, vartical_index+108+5), font, font_size,(255,255,255), font_boldness)\n",
        "\n",
        "          else:\n",
        "              predict_result = np.append(predict_result, 0)\n",
        "              #print(\"out\")\n",
        "\n",
        "    predict_result = predict_result.reshape(9,13)\n",
        "    #print(predict_result)\n",
        "\n",
        "    #Write for movie\n",
        "    mov_out.write(frame)\n",
        "\n",
        "    #if Esc Key is pushed, Escape loop\n",
        "    key = cv2.waitKey(INTERVAL)\n",
        "    if key == ESC_KEY:\n",
        "        break\n",
        "\n",
        "    #Load next video-frame\n",
        "    ret, frame = mov_org.read()\n",
        "\n",
        "#End\n",
        "cv2.destroyAllWindows()\n",
        "mov_org.release()\n",
        "mov_out.release()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsEq_HRn5oo2",
        "colab_type": "code",
        "outputId": "7dfa5dfe-4969-4d0d-da8a-f73a9b920e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "root_dir=\"./gdrive/My Drive/Google Colab/CO191219_proj\"\n",
        "#Load saved-model\n",
        "model = model_from_json(open(root_dir+'/Conv2D3-Dence3-Adadelta_v3/img_predict_Conv2D3-Dence3-Adadelta.json').read())\n",
        "#Load saved-weight\n",
        "model.load_weights(root_dir+'/Conv2D3-Dence3-Adadelta_v3/img_predict_Conv2D3-Dence3-Adadelta.hdf5')\n",
        "#Define categories\n",
        "categories = [\"floor1\", \"floor2\", \"floor-object\", \"object\", \"wall\", \"hole\", \"human\",\"ceiling\"]\n",
        "\n",
        "#Load image\n",
        "img_path = root_dir + \"/ImageforLearn_v2\" + str(input())\n",
        "img = image.load_img(img_path,target_size=(60, 70, 3))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#Predict\n",
        "features = model.predict(x)\n",
        "print(features)\n",
        "\n",
        "max_features = np.amax(features)\n",
        "\n",
        "#Output message\n",
        "if max_features == 0:\n",
        "    print(\"error\")\n",
        "elif features[0,0] == max_features:\n",
        "    print (categories[0])\n",
        "elif features[0,1] == max_features:\n",
        "    print (categories[1])\n",
        "elif features[0,2] == max_features:\n",
        "    print (categories[2])\n",
        "elif features[0,3] == max_features:\n",
        "    print (categories[3])\n",
        "elif features[0,4] == max_features:\n",
        "    print (categories[4])\n",
        "elif features[0,5] == max_features:\n",
        "    print (categories[5])\n",
        "elif features[0,6] == max_features:\n",
        "    print (categories[6])\n",
        "elif features[0,7] == max_features:\n",
        "    print (categories[7])\n",
        "else:\n",
        "    print(\"error\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/floor1/_0_1.jpg\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}